- This real-time system was designed to recognize printed texts pointed to by our finger and convert the recognized word to an audio output, and all of this while ensuring that the execution is happening in real-time with no deadlines being missed. This could enable visually-impaired people to ‘read’ non-braille books and could aid people with learning difficulties by providing them with a different approach to read.
- There were 4 real-time deadlines in this project that included capturing the image frame, using image processing manoeuvres to extract the small area around our finger-tip, run a text extraction OCR engine on the small extracted image area to get the corresponding words and then passing them through a speech synthesizer open-source tool namely eSpeak to get a speech output of the detected word through the speaker. To manage the 4 deadlines, each of these was put into a thread and these 4 threads were scheduled by a Rate-Monotonic scheduler with the help of semaphores for exclusive access to certain resources.
- The scheduling follows a FIFO policy in case of a tie in priorities and the POSIX API used in this project lends determinism to the Embedded Linux operating system I am using on the NVIDIA Jetson TX1 single-board computer for scheduling and resource management.
- By assigning processor core affinity, all the threads run on a single core and running Cheddar analysis on the WCETs of all services proves that this service set is indeed feasible – further corroborated by the necessary and sufficient Scheduling point test and Completion test that prove that this sequence is schedulable and no deadlines are being missed.
